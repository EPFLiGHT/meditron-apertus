# ========================
# Model & Paths
# ========================
base_model: /capstor/store/cscs/swissai/a127/apertus/huggingface/Apertus70B
output_dir: /capstor/store/cscs/swissai/a127/meditron/models/Meditron-Apertus-70B-only-med-no-moove-part2
resume_from_checkpoint: /capstor/store/cscs/swissai/a127/meditron/models/Meditron-Apertus-70B-only-med-no-moove/checkpoint-81/

# ========================
# Hardware & Speed
# ========================
deepspeed: /users/theimer/meditron-apertus/axolotl_config/deepspeed.json
bf16: auto
tf32: false # SHOULD be true
flash_attention: true
flash_attn_rms_norm: true
flash_attn_fuse_qkv: false
xformers_attention: null
strict: false

# ========================
# Datasets
# ========================
chat_template: tokenizer_default
datasets:
  # -- Chat Datasets (Shared Config) --
  - &chat_config
    path: /capstor/store/cscs/swissai/a127/meditron/datasets/masked/miriad/miriad-4.4M.jsonl
    type: chat_template
    ds_type: json
    split: train
    field_messages: conversations
    field_human: human
    field_model: gpt
    roles:
      user: [human]
      assistant: [gpt]
      system: [system]
    message_property_mappings:
      role: from
      content: value

  - <<: *chat_config
    path: /capstor/store/cscs/swissai/a127/meditron/datasets/masked/meadow/meadow.jsonl

  - <<: *chat_config
    path: /capstor/store/cscs/swissai/a127/meditron/datasets/masked/medqa/medqa.jsonl

  - <<: *chat_config
    path: /capstor/store/cscs/swissai/a127/meditron/datasets/masked/medtext/medtext.jsonl

  - <<: *chat_config
    path: /capstor/store/cscs/swissai/a127/meditron/datasets/masked/pubmedqa/pubmedqa.jsonl

  - <<: *chat_config
    path: /capstor/store/cscs/swissai/a127/meditron/datasets/masked/medmcqa/medmcqa.jsonl

  - <<: *chat_config
    path: /capstor/store/cscs/swissai/a127/meditron/datasets/masked/wikidoc_qa/wikidoc_qa.jsonl

  # -- Completion Datasets --
  - path: /capstor/store/cscs/swissai/a127/meditron/datasets/pretrain/guidelines/guidelines.jsonl
    ds_type: json
    type: completion
    field: text

  - path: /capstor/store/cscs/swissai/a127/meditron/datasets/pretrain/pubmed/pubmed_3B.jsonl
    ds_type: json
    type: completion
    field: text

dataset_processes: 128
shuffle_merged_datasets: true

# ========================
# Training Hyperparameters
# ========================
type: AutoModelForCausalLM
tokenizer_type: AutoTokenizer
sequence_len: 4096
sample_packing: false # SHOULD be true
pad_to_sequence_len: true
group_by_length: false
train_on_inputs: false

num_epochs: 1
micro_batch_size: 4
gradient_accumulation_steps: 8
max_grad_norm: 1.0

# ========================
# Optimization
# ========================
optimizer: adamw_torch
optim_args:
  fused: true
learning_rate: 1.0e-5
lr_scheduler: cosine
cosine_min_lr_ratio: 0.1
warmup_ratio: 0.0 #SHOULD have a warmup eg 0.3
weight_decay: 0.05

gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false

# ========================
# Quantization (Disabled)
# ========================
load_in_4bit: false
load_in_8bit: false

# ========================
# Logging & Evaluation
# ========================
logging_steps: 1
saves_per_epoch: 4
evals_per_epoch: 0 #SHOULD be 4
eval_set_size: 0.0 # SHOULD be 0.01
eval_table_size: null
early_stopping_patience: null

wandb_project: Meditron Apertus
wandb_entity: alexs-team
wandb_name: Meditron-Apertus-70B-only-med-no-moove
wandb_log_model: null
wandb_watch: null